# sdk/agent

Agent loop, tool registry, and turn orchestration. The brain that connects LLM, tools, and messaging.

## Origin

Port of [pi-agent](https://github.com/badlogic/pi-mono/tree/main/packages/agent) (`@mariozechner/pi-agent-core`) patterns to Go.

**Reference files in pi-mono:**
- `packages/agent/src/agent-loop.ts` â€” the turn cycle (core loop)
- `packages/agent/src/agent.ts` â€” Agent class, tool management, context
- `packages/agent/src/types.ts` â€” AgentTool, events, config
- `packages/coding-agent/src/core/agent-session.ts` â€” real-world retry/compaction
- `packages/coding-agent/src/core/system-prompt.ts` â€” prompt construction
- `packages/coding-agent/src/core/tools/*.ts` â€” concrete tool implementations

## Architecture

```
sdk/agent/
â”œâ”€â”€ agent.go        # Agent struct, Run() main loop
â”œâ”€â”€ registry.go     # Tool registration and execution
â”œâ”€â”€ context.go      # Conversation history management + hooks
â”œâ”€â”€ logger.go       # Structured event logging
â””â”€â”€ config.go       # LoadConfig() from env vars
```

### The turn cycle

This is the heart. Ported from `agent-loop.ts`:

```
â”Œâ”€ telegram.Poll() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                      â”‚
â”‚  for each message:                                   â”‚
â”‚    1. Identify user + role (DB lookup)               â”‚
â”‚    2. Append user message to history                 â”‚
â”‚    3. Transform context (apply hooks)                â”‚
â”‚    4. llm.Chat(system, messages, tools)              â”‚
â”‚         â”‚                                            â”‚
â”‚         â”œâ”€ Response.Type == "text"                   â”‚
â”‚         â”‚    â†’ send to Telegram, done                â”‚
â”‚         â”‚                                            â”‚
â”‚         â””â”€ Response.Type == "tool_use"               â”‚
â”‚              for each tool_call:                     â”‚
â”‚                validate args (JSON Schema)           â”‚
â”‚                execute handler                       â”‚
â”‚                  â”œâ”€ success â†’ ToolResult             â”‚
â”‚                  â””â”€ error â†’ ToolResult(isError=true) â”‚
â”‚              append all ToolResults to history        â”‚
â”‚              â†’ loop back to step 4                   â”‚
â”‚                                                      â”‚
â”‚    5. Persist telegram offset                        â”‚
â”‚    6. Log everything                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key insight from pi-agent:** tool errors don't crash the agent. They become structured `ToolResult{IsError: true}` messages that the LLM receives and can reason about ("the schedule query failed because no date was provided, let me ask the user").

### Tool registry

```go
type ToolHandler func(ctx ToolContext, args json.RawMessage) (string, error)

type ToolContext struct {
    UserID    int64
    Role      string  // "manager" or "cleaner"
    HotelID   string
    Timestamp int64
    DB        *store.DB
}

type ToolRegistry struct { ... }

func (r *ToolRegistry) Register(name, description string, schema json.RawMessage, handler ToolHandler)
func (r *ToolRegistry) Execute(name string, args json.RawMessage, ctx ToolContext) (*llm.ToolResult, error)
func (r *ToolRegistry) Definitions() []llm.ToolDef  // for passing to LLM
```

**pi-agent pattern:** tools are registered at startup with `setTools([...])`. Each tool has a name, description, JSON Schema, and an execute function. The registry converts them to `llm.ToolDef` for the LLM and routes execution by name.

**Access control:** the `ToolContext` carries the user's role. Tool handlers check it:
```go
func handleUpdateSchedule(ctx ToolContext, args json.RawMessage) (string, error) {
    if ctx.Role != "manager" {
        return "", fmt.Errorf("only managers can update the schedule")
    }
    // ...
}
```

### Context management

Conversation history with hooks for transformation:

```go
type ContextManager struct {
    Messages    []llm.Message
    MaxMessages int  // simple truncation (keep last N)

    // Hooks (future extensibility)
    TransformContext func([]llm.Message) []llm.Message
    ConvertToLLM     func([]llm.Message) []llm.Message
}
```

**From pi-agent:** the core agent doesn't own context-window policy. It exposes hooks:
- `TransformContext` â€” called before each LLM call, can prune/compact/summarize
- `ConvertToLLM` â€” filters out app-internal messages before sending to provider

**MVP:** simple truncation (keep last 20 messages). Future: summarization-based compaction like `coding-agent` does.

### Logger

Structured logging for every significant action:

```go
type Logger struct { ... }

func (l *Logger) Inbound(userID int64, text string)
func (l *Logger) LLMCall(model string, tokensIn, tokensOut int, durationMs int64)
func (l *Logger) ToolExec(tool string, durationMs int64, success bool)
func (l *Logger) Outbound(chatID int64, text string)
func (l *Logger) Error(context string, err error)
```

Output: stdout (for orchestrator) + `events` table in SQLite (for analysis during demo phase).

### Config

```go
type Config struct {
    TelegramToken string  // env: TELEGRAM_BOT_TOKEN
    LLMKey        string  // env: LLM_API_KEY
    LLMModel      string  // env: LLM_MODEL (default: claude-sonnet-4-5-20250514)
    DBPath        string  // env: DB_PATH (default: /data/state.db)
    HotelName     string  // env: HOTEL_NAME
    Timezone      string  // env: TIMEZONE (default: Europe/Rome)
    LogLevel      string  // env: LOG_LEVEL (default: info)
    MaxTokens     int     // env: LLM_MAX_TOKENS (default: 1024)
    PollTimeout   int     // env: POLL_TIMEOUT (default: 30)
}

func LoadConfig() (*Config, error)  // reads from env vars
```

## What we took from pi-agent

| pi-agent feature | sdk/agent | Notes |
|-----------------|-----------|-------|
| Turn cycle (LLM â†’ tools â†’ continue) | âœ… Ported | Core loop identical |
| Tool registry + execute | âœ… Ported | Same pattern, Go types |
| Error â†’ structured ToolResult | âœ… Ported | Key resilience pattern |
| Context hooks (transform/convert) | âœ… Ported | As function fields |
| System prompt (mutable) | âœ… Ported | Set at init, changeable |
| Event logging | âœ… Ported | Simplified (no event bus) |

## What we deferred (but can add later)

| pi-agent feature | Status | When to add |
|-----------------|--------|-------------|
| Streaming turns with live events | ðŸ”® | Web dashboard / real-time UI |
| Session tree (branching/forking) | ðŸ”® | Multi-turn exploration |
| Extension system (plugins) | ðŸ”® | When agents need runtime extensibility |
| Steering queue (inject mid-turn) | ðŸ”® | When we need external interrupts |
| Compaction (summarize old context) | ðŸ”® | When conversations exceed context window |
| Follow-up queue | ðŸ”® | When we need chained prompts |
| Multi-modal tool results (images) | ðŸ”® | When tools return visual data |

### Adding compaction (future)

When conversations get long, implement a `TransformContext` hook:

```go
agent.Context.TransformContext = func(msgs []llm.Message) []llm.Message {
    if len(msgs) > 50 {
        // Summarize first 40 messages into one, keep last 10
        summary := summarize(msgs[:40])
        return append([]llm.Message{summary}, msgs[40:]...)
    }
    return msgs
}
// Reference: packages/coding-agent/src/core/agent-session.ts (compaction logic)
```

### Adding streaming (future)

Change `llm.Provider.Chat()` to return a channel of events:

```go
type StreamEvent struct {
    Type string  // "text_delta", "toolcall_delta", "done", "error"
    Data string
}
// Reference: packages/ai/src/stream.ts (event model)
```

## Status

ðŸ”´ **Not started** â€” architecture and interfaces defined. Next: implement after sdk/llm.
